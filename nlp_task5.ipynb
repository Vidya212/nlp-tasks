{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOM/zmL+OSBiY+PG5TcF31s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vidya212/nlp-tasks/blob/main/nlp_task5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import random\n",
        "import nltk\n",
        "from nltk.corpus import stopwords, reuters\n",
        "from collections import Counter, defaultdict\n",
        "from nltk import FreqDist, ngrams\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('reuters')\n",
        "sents = reuters.sents()\n",
        "\n",
        "stop_word = set(stopwords.words('english'))\n",
        "removal_list = list(stop_word) + list(string.punctuation) + ['\\t', 'rt']\n",
        "\n",
        "unigram = []\n",
        "bigram = []\n",
        "trigram = []\n",
        "for sentence in sents:\n",
        "    sentence = [word.lower() for word in sentence if word != '.']\n",
        "    unigram.extend(sentence)\n",
        "    bigram.extend(list(ngrams(sentence, 2, pad_left=True, pad_right=True)))\n",
        "    trigram.extend(list(ngrams(sentence, 3, pad_left=True, pad_right=True)))\n",
        "\n",
        "def remove_stopwords(items):\n",
        "    filtered = []\n",
        "    for item in items:\n",
        "        if isinstance(item, tuple):\n",
        "            if all(word not in removal_list and word is not None for word in item):\n",
        "                filtered.append(item)\n",
        "        else:\n",
        "            if item not in removal_list:\n",
        "                filtered.append(item)\n",
        "    return filtered\n",
        "unigram = remove_stopwords(unigram)\n",
        "bigram = remove_stopwords(bigram)\n",
        "trigram = remove_stopwords(trigram)\n",
        "freq_uni = FreqDist(unigram)\n",
        "freq_bi = FreqDist(bigram)\n",
        "freq_tri = FreqDist(trigram)\n",
        "d = defaultdict(Counter)\n",
        "for (a, b, c), freq in freq_tri.items():\n",
        "    if a is not None and b is not None and c is not None:\n",
        "        d[(a, b)][c] += freq\n",
        "def pick_word(counter, fallback_list):\n",
        "    \"Choose a random element weighted by frequency, with a fallback.\"\n",
        "    if counter:\n",
        "        return random.choice(list(counter.elements()))\n",
        "    elif fallback_list:\n",
        "        return random.choice(fallback_list)\n",
        "    else:\n",
        "        return \"the\"\n",
        "prefix = (\"he\", \"is\")\n",
        "s = list(prefix)\n",
        "print(\" \".join(s))\n",
        "for _ in range(19):\n",
        "    suffix = pick_word(d[prefix], unigram)\n",
        "    s.append(suffix)\n",
        "    print(\" \".join(s))\n",
        "    prefix = (prefix[1], suffix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AC0x9RUGG3g_",
        "outputId": "0cacd3fa-311a-4280-f84e-c339080be41e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]   Package reuters is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "he is\n",
            "he is six\n",
            "he is six five\n",
            "he is six five large\n",
            "he is six five large prospective\n",
            "he is six five large prospective new\n",
            "he is six five large prospective new 18\n",
            "he is six five large prospective new 18 200\n",
            "he is six five large prospective new 18 200 railways\n",
            "he is six five large prospective new 18 200 railways aimed\n",
            "he is six five large prospective new 18 200 railways aimed asking\n",
            "he is six five large prospective new 18 200 railways aimed asking class\n",
            "he is six five large prospective new 18 200 railways aimed asking class money\n",
            "he is six five large prospective new 18 200 railways aimed asking class money branch\n",
            "he is six five large prospective new 18 200 railways aimed asking class money branch corp\n",
            "he is six five large prospective new 18 200 railways aimed asking class money branch corp rates\n",
            "he is six five large prospective new 18 200 railways aimed asking class money branch corp rates company\n",
            "he is six five large prospective new 18 200 railways aimed asking class money branch corp rates company index\n",
            "he is six five large prospective new 18 200 railways aimed asking class money branch corp rates company index mln\n",
            "he is six five large prospective new 18 200 railways aimed asking class money branch corp rates company index mln contracted\n"
          ]
        }
      ]
    }
  ]
}